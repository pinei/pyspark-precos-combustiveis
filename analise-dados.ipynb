{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e89c6f-fd86-4a00-a408-7b7408fb996a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Coleta de dados\n",
    "\n",
    "Esse projeto em PySpark faz uma análise de dados de preços de combustíveis da ANP.\n",
    "\n",
    "O trabalho faz uso de dados publicados pela ANP (Agência Nacional de Petróleo)\n",
    "\n",
    "> Em cumprimento às determinações da Lei do Petróleo (Lei nº 9478/1997, artigo 8º), a ANP acompanha os preços praticados por revendedores de combustíveis automotivos e de gás liquefeito de petróleo envasilhado em botijões de 13 quilos (GLP P13), por meio de uma pesquisa semanal de preços realizada por empresa contratada.\n",
    "\n",
    "- [Série Histórica de Preços de Combustíveis e de GLP](https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/serie-historica-de-precos-de-combustiveis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7692d95-c2b6-4aa7-90a8-7c31e0f7b1d6",
   "metadata": {},
   "source": [
    "Coletamos a série histórica de \"Combustíveis automotivos\" que vai de 2004 a 2023. São 39 arquivos CSV totalizando aproximadamente 3.7 GB.\n",
    "\n",
    "![Amostra dos dados](./assets/amostra_planilha_revenda.png)\n",
    "\n",
    "- [Metadados em PDF](https://www.gov.br/anp/pt-br/centrais-de-conteudo/dados-abertos/arquivos/shpc/metadados-serie-historica-precos-combustiveis-1.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b34829c-90ef-4e35-b5b2-2479a566f0fe",
   "metadata": {},
   "source": [
    "Temos as seguintes colunas nos arquivos CSV, em conformidade com a documentação de metadados:\n",
    "\n",
    "| Coluna            | Tipo    | Comentário                                                                           |\n",
    "| ----------------- | ------- | ------------------------------------------------------------------------------------ |\n",
    "| Regiao            | Texto   | Sigla da região do país (ex: S, N, SE)                                               |\n",
    "| Estado            | Texto   | Sigla de unidade federativa (ex: RJ, SP, MG)                                         |\n",
    "| Municipio         | Texto   | Nome de município                                                                    |\n",
    "| Revenda           | Texto   | Razão social do revendedor de combustível                                            |\n",
    "| CNPJ da Revenda   | Texto   | CNPJ do revendedor                                                                   |\n",
    "| Nome da Rua       | Texto   | Logradouro                                                                           |\n",
    "| Numero Rua        | Texto   | Logradouro                                                                           |\n",
    "| Complemento       | Texto   | Logradouro                                                                           |\n",
    "| Bairro            | Texto   | Logradouro                                                                           |\n",
    "| CEP               | Texto   | Código de Endereçamento Postal                                                       |\n",
    "| Produto           | Texto   | Produto combustível (ex: GASOLINA, ETANOL, DIESEL)                                   |\n",
    "| Data da Coleta    | Data    | Data da pesquisa de preço (formato dd/mm/aaaa)                                       |\n",
    "| Valor de Venda    | Decimal | Valor de venda da unidade de combustível (4 casas decimais, vírgula como separador)  |\n",
    "| Valor de Compra   | Decimal | Valor de compra da unidade de combustível (4 casas decimais, virgula como separador) |\n",
    "| Unidade de Medida | Texto   | Unidade ao qual os valores de compra e venda se referem (ex: R$ / litro)             |\n",
    "| Bandeira          | Texto   | Nome de marca do posto de revenda (ex: IPIRANGA, BRANCA, COSAN, etc.)                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77acdcc-ce95-4c24-b234-15a5b5ac5b8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Infraestrutura\n",
    "\n",
    "Aproveitando a configuração de cluster da Google Cloud Platform criada para o [projeto Hadoop](https://github.com/pinei/hadoop-precos-combustiveis), incluímos o JupyterLab para trabalhar com o PySpark.\n",
    "\n",
    "![cluster-info](./assets/cluster_info.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda0644-a8f3-4dd6-9280-de847557dbc8",
   "metadata": {},
   "source": [
    "Em paralelo usamos uma instalação em Raspberry Pi 4 para verificar a viabilidade e desempenho nesse tipo de hardware de baixo custo.\n",
    "\n",
    "- [Running PySpark in JupyterLab on a Raspberry Pi](https://dev.to/pinei/running-pyspark-in-jupyterlab-on-a-raspberry-pi-1293)\n",
    "\n",
    "Por rodar no modo standalone, vamos chamar este ambiente de \"máquina local\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a0f7c5-47e4-4d38-855d-63edb15a9667",
   "metadata": {
    "tags": []
   },
   "source": [
    "Em projeto anterior os arquivos CSV foram organizados em um bucket do Google Cloud Storage.\n",
    "\n",
    "> `https://console.cloud.google.com/storage/browser/hadoop-dados-brutos`\n",
    "\n",
    "No cluster Dataproc o Spark tem acesso padrão aos arquivos desse storage via URL `gs://hadoop-dados-brutos`, podendo inclusive fazer o processamento distribuído entre os nós."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d7a84-53ad-40fe-a906-9870d3021602",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'gs://hadoop-dados-brutos'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557042d-ff4b-4a40-8b0f-3a84075d3779",
   "metadata": {},
   "source": [
    "No Spark em máquina local, o suporte a conexão com o mesmo storage precisa de configuração adicional.\n",
    "\n",
    "- [How to fix \"No FileSystem for scheme: gs\" in pyspark?](https://stackoverflow.com/questions/55595263/how-to-fix-no-filesystem-for-scheme-gs-in-pyspark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b7b02-8fc0-4361-8b82-13afeeb96f1b",
   "metadata": {},
   "source": [
    "## Iniciando a sessão do Spark\n",
    "\n",
    "Inicializamos uma sessão do Spark com suporte ao Hive para gerenciamento de metadados das bases de dados.\n",
    "\n",
    "Também habilitamos o suporte ao sistema de arquivos do Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068ec3f2-5c5c-43a5-9118-ecd60f055ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = ( SparkSession\n",
    "    .builder\n",
    "    .appName(\"analise-dados\")\n",
    "    .config(\"spark.jars\", \"https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop3-latest.jar\")\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate() )\n",
    "\n",
    "spark._jsc.hadoopConfiguration().set('fs.gs.impl', 'com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e35ed-9168-43e5-b369-0eff087d202b",
   "metadata": {},
   "source": [
    "O conector do Google precisa de uma chave para autenticação no serviço.\n",
    "\n",
    "Passo a passo para gerar a chave:\n",
    "- Console do Google Cloud Platform\n",
    "- APIs e Serviços > Credenciais\n",
    "- Criar Conta de Serviço\n",
    "- Criar Chave do tipo JSON\n",
    "\n",
    "> \"É feito o download de um arquivo contendo a chave privada. Armazene o arquivo com segurança porque essa chave não pode ser recuperada em caso de perda.\"\n",
    "\n",
    "Subimos o arquivo JSON para uma pasta de trabalho:\n",
    "\n",
    "> `/home/aldinei_bastos/work/seventh-abacus-395221-52fc140a5609.json`\n",
    "\n",
    "É necessário então localizar o JSON através de uma variável de ambiente `GOOGLE_APPLICATION_CREDENTIALS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49ee85e-23a6-44a3-8b90-7ac979e8d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HOME_DIR = os.environ[\"HOME\"]\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = f'{HOME_DIR}/work/seventh-abacus-395221-52fc140a5609.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1fc6d-1b77-4501-80d7-648bc523ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf99d92-6375-4481-a671-a836a6a322c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(name, comment):\n",
    "    spark.sql(f\"CREATE DATABASE IF NOT EXISTS {name} COMMENT '{comment}'\")\n",
    "    return spark.sql(f\"DESCRIBE DATABASE {name}\")\n",
    "\n",
    "metadata = create_database(\"precos_anp\", \"Base de dados de preços de combustíveis fornecidos pela ANP e alguns indicadores de mercado\")\n",
    "metadata.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dad6011-a790-42aa-97b6-87dbc1500481",
   "metadata": {},
   "source": [
    "## Ingestão\n",
    "\n",
    "Definimos o schema para leitura dos arquivos CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08551499-0669-4427-9033-396a1d700a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, DecimalType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Regiao\", StringType(), True),\n",
    "    StructField(\"Estado\", StringType(), True),\n",
    "    StructField(\"Municipio\", StringType(), True),\n",
    "    StructField(\"Revenda\", StringType(), True),\n",
    "    StructField(\"CNPJ da Revenda\", StringType(), True),\n",
    "    StructField(\"Nome da Rua\", StringType(), True),\n",
    "    StructField(\"Numero Rua\", StringType(), True),\n",
    "    StructField(\"Complemento\", StringType(), True),\n",
    "    StructField(\"Bairro\", StringType(), True),\n",
    "    StructField(\"CEP\", StringType(), True),\n",
    "    StructField(\"Produto\", StringType(), True),\n",
    "    StructField(\"Data da Coleta\", DateType(), True),\n",
    "    StructField(\"Valor de Venda\", DecimalType(10, 4), True),\n",
    "    StructField(\"Valor de Compra\", DecimalType(10, 4), True),\n",
    "    StructField(\"Unidade de Medida\", StringType(), True),\n",
    "    StructField(\"Bandeira\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_csv = spark.read.csv(f\"{DATA_PATH}/anp-combustiveis-automotivos/ca-*.csv\",\n",
    "                    header=True,\n",
    "                    schema=schema,\n",
    "                    sep=';',\n",
    "                    multiLine=True,\n",
    "                    quote='\"',\n",
    "                    dateFormat=\"dd/MM/yyyy\",\n",
    "                    locale='pt-BR')\n",
    "df_csv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677f2be-3208-4e96-97fc-8c0f96b334a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Criamos uma tabela gerenciada e populamos com os dados do dataframe carregado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47da75-7571-4b50-a068-807283c62e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS precos_anp.combustiveis_automotivos (\n",
    "      regiao STRING,\n",
    "      estado STRING,\n",
    "      municipio STRING,\n",
    "      revenda STRING,\n",
    "      cnpj_revenda STRING,\n",
    "      endereco_rua STRING,\n",
    "      endereco_numero STRING,\n",
    "      endereco_complemento STRING,\n",
    "      endereco_bairro STRING,\n",
    "      endereco_cep STRING,\n",
    "      mes STRING,\n",
    "      data DATE,\n",
    "      valor_venda DECIMAL(10,4),  -- Tipo decimal com até 4 casas decimais\n",
    "      valor_compra DECIMAL(10,4),  -- Tipo decimal com até 4 casas decimais\n",
    "      unidade_medida STRING,\n",
    "      bandeira STRING\n",
    "    )\n",
    "    PARTITIONED BY (produto STRING)\n",
    "    CLUSTERED BY (mes) INTO 8 BUCKETS\n",
    "\"\"\")\n",
    "\n",
    "# Checando\n",
    "spark.table('precos_anp.combustiveis_automotivos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4fcd1-1892-49d0-8ecc-c200b9564875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_ca = (\n",
    "    df_csv.select(\n",
    "        F.column(\"Regiao\").alias(\"regiao\"),\n",
    "        F.column(\"Estado\").alias(\"estado\"),\n",
    "        F.column(\"Municipio\").alias(\"municipio\"),\n",
    "        F.column(\"Revenda\").alias(\"revenda\"),\n",
    "        F.column(\"CNPJ da Revenda\").alias(\"cnpj_revenda\"),\n",
    "        F.column(\"Nome da Rua\").alias(\"endereco_rua\"),\n",
    "        F.column(\"Numero Rua\").alias(\"endereco_numero\"),\n",
    "        F.column(\"Complemento\").alias(\"endereco_complemento\"),\n",
    "        F.column(\"Bairro\").alias(\"endereco_bairro\"),\n",
    "        F.column(\"CEP\").alias(\"endereco_cep\"),\n",
    "        F.column(\"Produto\").alias(\"produto\"),\n",
    "        F.column(\"Data da Coleta\").alias(\"data\"),\n",
    "        F.column(\"Valor de Venda\").alias(\"valor_venda\"),\n",
    "        F.column(\"Valor de Compra\").alias(\"valor_compra\"),\n",
    "        F.column(\"Unidade de Medida\").alias(\"unidade_medida\"),\n",
    "        F.column(\"Bandeira\").alias(\"bandeira\")\n",
    "    )\n",
    "    .withColumn(\"produto\", F.when(F.col(\"produto\") == \"ETANO\", \"ETANOL\").otherwise(F.col(\"produto\")))\n",
    "    .withColumn(\"mes\", F.date_format(\"data\", \"yyyy-MM\"))\n",
    ")\n",
    "\n",
    "df_ca.write.mode(\"overwrite\").saveAsTable(\"precos_anp.combustiveis_automotivos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
